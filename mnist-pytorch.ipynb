{"cells":[{"metadata":{},"cell_type":"markdown","source":"# MNIST "},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install jovian --upgrade --quiet\n#import jovian\n#jovian.commit(project='MNIST_Pytorch', environment=None)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Numerical computation and visualization libraries \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n# Pytorch Libraries\nimport torch\nimport torchvision\nimport torchvision.transforms as tr\nimport torch.nn as nn\nfrom torch.utils.data import random_split\nimport torch.optim as optim\nfrom torchvision import models\nimport copy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Dataset \n\ntrainset = torchvision.datasets.MNIST(root='./data',\n                                      train=True,\n                                      download=True,\n                                      #transform=tr.ToTensor()\n                                      )\n\n\ntestset = torchvision.datasets.MNIST(root='./data',\n                                     train=False,\n                                     download=True,\n                                     #transform=tr.ToTensor()\n                                    )\n\nprint('Len of train dataset ',len(trainset))\nprint('Len of test dataset ',len(testset))\nprint('-'*30)\nprint(trainset)\nprint(testset)\nprint('-'*30)\nprint(trainset[0])\nprint(testset[0])\nprint('-'*30)\ntrainset[0][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading images and labels for fifth item dataitem\n\nimage , label = trainset[4]\nplt.imshow(image,cmap='gray')\nprint('Label :',label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig , ax = plt.subplots(nrows=2,ncols=3,figsize=(10,10))\n\nimage , label = trainset[0]\nax[0,0].imshow(image)\nax[0,0].set_title(label)\nax[0,0].axis('off')\n\nimage , label = trainset[1]\nax[0,1].imshow(image)\nax[0,1].set_title(label)\nax[0,1].axis('off')\n\nimage , label = trainset[2]\nax[0,2].imshow(image)\nax[0,2].set_title(label)\nax[0,2].axis('off')\n\nimage , label = trainset[3]\nax[1,0].imshow(image)\nax[1,0].set_title(label)\nax[1,0].axis('off')\n\nimage , label = trainset[4]\nax[1,1].imshow(image)\nax[1,1].set_title(label)\nax[1,1].axis('off')\n\nimage , label = trainset[5]\nax[1,2].imshow(image)\nax[1,2].set_title(label)\nax[1,2].axis('off')\n\nplt.tight_layout(pad=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting the Dataset into tensors\n\ntrainset = torchvision.datasets.MNIST(root='./data',\n                                      train=True,\n                                      download=True,\n                                      transform=tr.ToTensor()\n                                      )\n\n\ntestset = torchvision.datasets.MNIST(root='./data',\n                                     train=False,\n                                     download=True,\n                                     transform=tr.ToTensor()\n                                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the data into train and validation set\n\ntrainset , valset = random_split(trainset,[50000,10000])\nlen(trainset),len(valset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size= 256\n\ntrainloader = torch.utils.data.DataLoader(trainset,\n                                          batch_size=batch_size,\n                                          shuffle=True)\n\nvalloader = torch.utils.data.DataLoader(valset,\n                                          batch_size=batch_size,\n                                          shuffle=False)\n\ntestloader = torch.utils.data.DataLoader(testset,\n                                          batch_size=batch_size,\n                                          shuffle=False)\n\nclasses = ('0','1','2','3','4','5','6','7','8','9')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images , labels= next(iter(trainloader))\nprint(images.shape)\nprint(images[1].shape)\nprint(labels[1].item())\n\nplt.figure(figsize=(8,16))\ndef imshow(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg,(1,2,0)))\n    plt.show()\n    \n    \nimshow(torchvision.utils.make_grid(images))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting images \n\nplt.figure(figsize=(10,10))\nplt.subplot(321)\nfor i in range(25):\n    ax1 = plt.subplot(5,5,i+1)\n    plt.imshow(images[i+1].reshape(28,28).detach().numpy(),cmap='gray')\n    #plt.title(labels[i+1].item())\n    plt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train LeNet"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining a custom LeNet module\n\nclass LeNet(nn.Module):                         # Extending nn.Module class \n    def __init__(self):                         # Constructor \n        super(LeNet,self).__init__()            # Calls the constructor of nn.Module\n        self.cnn_model = nn.Sequential(         # nn.Sequentila allows multiple layers to stack together\n            nn.Conv2d(1,6,5),                   #(N,1,28,28) -> (N,6,24,24)\n            nn.Tanh(),                      \n            nn.AvgPool2d(2,stride=2),           #(N,6,24,24) -> (N,6,12,12)\n            nn.Conv2d(6,16,5),                  #(N,6,12,12) -> (N,16,8,8)\n            nn.Tanh(),\n            nn.AvgPool2d(2,stride=2)            #(N,16,8,8) -> (N,16,4,4)\n            )\n        \n        self.fc_model = nn.Sequential(          # Fully connected layer \n            nn.Linear(256,120),\n            nn.Tanh(),\n            nn.Linear(120,84),\n            nn.Tanh(),\n            nn.Linear(84,10)\n        \n            )\n        \n# It get a batch of data which have defined earlier \n        \n    def forward(self,x):     \n        #print(x.shape)\n        x = self.cnn_model(x)       \n        #print(x.shape)\n        x = x.view(x.size(0),-1)    # Flatning the inputs from tensors to vectors \n        #print(x.shape)\n        x = self.fc_model(x)        # Passing the conv layer to fully connected layer\n        #print(x.shape)\n        return x\n    \nnet = LeNet()#.to(device)\nnet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(net.fc_model[4].weight.shape,net.fc_model[4].bias.shape)\n#list(net.parameters())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate on the basics of accuracy\n\ndef evaluation(dataloader):\n    total , correct = 0,0\n    for data in dataloader:\n        inputs , labels = data\n        inputs , labels = inputs.to(device) , labels.to(device)\n        output = net(inputs)            \n        max_pred,pred = torch.max(output.data,dim=1)\n        total +=labels.size(0)\n        correct +=(pred == labels).sum().item()  \n    return 100 * correct / total","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = LeNet().to(device)           # Creating object for LeNet() model and passing it to GPU \n\nloss_fn = nn.CrossEntropyLoss()    # It takes the highest value which is the predictions and mark it as 1\n                                   # And mark rest of the values as zeros. \nopt = optim.Adam(net.parameters()) # Using adam Optimization algorithm , we can also specify the hyperparameters .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the model and perform the training process \n\n%time\ndef fit(max_epochs =16):\n    \n    loss_arr = []\n    loss_epoch_arr = []\n    \n    for epoch in range(max_epochs):\n        for i, data in enumerate(trainloader,0): # Iterating through the train loader \n            inputs,labels = data\n            inputs,labels = inputs.to(device),labels.to(device)\n\n            opt.zero_grad()     # Reset the gradient in every iteration\n\n            outputs = net(inputs)\n            loss = loss_fn(outputs,labels)   # Loss forward pass\n            loss.backward()                  # Loss backaed pass\n            opt.step()                       # Update all the parameters by the given learnig rule\n\n            loss_arr.append(loss.item())\n        loss_epoch_arr.append(loss.item())\n        print('Val accuracy: %0.2f , Train accuracy : %0.2f'%(evaluation(valloader),evaluation(trainloader)))\n\n    plt.plot(loss_epoch_arr)\n    plt.show()\n    \nfit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here we are visualiizing the behaviour of image in the first layer () of LeNet Architecture \n\nnet = net.to('cpu')                    # Taking the model back to the CPU \nout = net.cnn_model[0](images)\nprint('Image Shape :',out.shape)\nimage_id = 3\n\nplt.figure(figsize=(6,6))\nplt.subplot(321)\nfor i in range(6):\n    ax1 = plt.subplot(3,2,i+1)\n    plt.imshow(out[image_id,i,:,:].detach().numpy(),cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img , label = testset[0]\nplt.imshow(img[0],cmap='gray')\nprint('Shape :',img.shape)\nprint('Label :',label)\nprint(img.unsqueeze(0).shape)\n\n# img.unsqueeze simply adds another dimension at the begining of the 1x28x28 \n# tensor, making it a 1x1x28x28 tensor, which the model views as a batch containing a single image.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function which loads the prediction of our model\n\ndef predict_image(img,model):\n    xb = img.unsqueeze(0)\n    yb = net(xb)\n    _,pred = torch.max(yb,dim=1)\n    return pred[0].item()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img , label = testset[16]\nplt.imshow(img[0],cmap='gray')\nprint('Label :',label,'Predicted',predict_image(img,net))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function which loads the prediction of our model\n\ndef predict_image(img,model):              # Here we are giving an input  tensor\n    xb = img.unsqueeze(0)                  # Adding another dimention because our model accepts a bath\n    yb = net(xb)                           # Passing the bacth into the model\n    _,pred = torch.max(yb,dim=1)           # Getting the prediction from output (_ : will give the max prob and prob : will give the index of highest prob)              \n    return pred[0].item()\n\n# View the actual label and prediction of our model\n\nplt.figure(figsize=(12,12))\nplt.subplot(321)\nfor i in range(25):\n    ax1 = plt.subplot(5,5,i+1)\n    img , label = testset[i+1]\n    plt.imshow(img[0],cmap='gray')\n    if predict_image(img,net) == label:\n        color = 'green'\n    else:\n        color = 'red'\n    \n    \n    plt.xticks([])\n    plt.yticks([])\n    plt.tight_layout(pad=2)\n    plt.title('Pred:{},True:{}'.format(predict_image(img,net),label),color=color)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(net.state_dict(), 'mnist-ResNet.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}